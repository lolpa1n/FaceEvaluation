{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy1 of FaceEvaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lolpa1n/FaceEvaluation/blob/master/FaceEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ2SVUXre4fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip uninstall -y tensorflow\n",
        "!pip3 install tensorflow-gpu==1.14 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n-rZ0cmdT9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "\n",
        "get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YhIdULCFa8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/'My Drive'/crop_net_new.zip /content/sample_data/\n",
        "!unzip -q \"/content/sample_data/crop_net_new.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcbhXfWVhf5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, GlobalAveragePooling2D, BatchNormalization, Activation\n",
        "from keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJbdfJ4K9HLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def insert_in_background(image, size):\n",
        "    im_h = image.shape[0]\n",
        "    im_w = image.shape[1]\n",
        "    \n",
        "    bg_h, bg_w = size\n",
        "    background =  np.zeros((bg_h, bg_w, 3), dtype=np.int)\n",
        "    \n",
        "    for i in range(3):\n",
        "        background[:im_h, :im_w, i] = image[:,:, i]\n",
        "        \n",
        "    return background\n",
        "  \n",
        "def resize_and_padding(image, size):\n",
        "    \n",
        "    im_h = image.shape[0]\n",
        "    im_w = image.shape[1]\n",
        "    \n",
        "    bg_h, bg_w = size\n",
        "    background =  np.zeros((bg_h, bg_w, 3), dtype=np.int)\n",
        "    \n",
        "    if im_h > im_w:\n",
        "        koef = im_h/bg_h\n",
        "        \n",
        "        new_w = int(im_w / koef)\n",
        "        new_h = int(im_h / koef)\n",
        "        \n",
        "        image = cv2.resize(image, (new_w, new_h))\n",
        "    else:\n",
        "        koef = im_w/bg_w\n",
        "        \n",
        "        new_h = int(im_h / koef)\n",
        "        new_w = int(im_w / koef)\n",
        "        \n",
        "        image = cv2.resize(image, (new_w, new_h))\n",
        "        \n",
        "    for i in range(3):\n",
        "        background[:new_h, :new_w, i] = image[:,:, i]\n",
        "    \n",
        "    return background\n",
        "  \n",
        "def resize_image(image, size):\n",
        "  return resize_and_padding(image, size)\n",
        "\n",
        "      \n",
        "\n",
        "import pathlib\n",
        "new_dir = '/content/crop_net/'\n",
        "pathlib.Path(new_dir).mkdir(parents=True, exist_ok=True) \n",
        "\n",
        "def convert_image(path, file):\n",
        "  img = cv2.imread(path + file)\n",
        "  img = resize_image(img, (224, 224))\n",
        "  cv2.imwrite(new_dir + file, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr_mWh1Pgu_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_H = 224\n",
        "IMG_W = 224\n",
        "IMG_C = 3\n",
        "\n",
        "def read_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (IMG_W, IMG_H))\n",
        "    if IMG_C == 1:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = img.reshape(img.shape[0], img.shape[1], 1)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(float)\n",
        "    img /= 255\n",
        "    return img\n",
        "  \n",
        "directory = '/content/crop_net_new/'\n",
        "files = os.listdir(directory)\n",
        "\n",
        "data = pd.DataFrame(columns=['path', 'proba'])\n",
        "\n",
        "for i, file in enumerate(files):\n",
        "    info = file.split('_')\n",
        "    views = int(info[2])\n",
        "    likes = int(info[3])\n",
        "    friends = int(info[4].split('.')[0])\n",
        "    \n",
        "    img = cv2.imread(directory + file)\n",
        "    if img.shape[0] < IMG_H/3 and img.shape[1] < IMG_W/3:\n",
        "      continue\n",
        "    \n",
        "    proba = 0.95 if likes / views > 0.95 else likes / views\n",
        "    \n",
        "    path = new_dir + file\n",
        "    try:\n",
        "      convert_image(directory, file)\n",
        "      data = data.append({'path': path, 'proba': proba}, ignore_index = True)\n",
        "    except:\n",
        "      print(file)\n",
        "data = data.drop(data[data['proba'] > 0.5].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4SyEuElgvPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, data_test = train_test_split(data, test_size=0.1, random_state=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSSfi_dJaiCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train.shape, data_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYSf8SP-loge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=data_train,\n",
        "                                              x_col=\"path\", y_col=\"proba\", has_ext=True, \n",
        "                                              class_mode=\"other\", target_size=(IMG_H, IMG_W), \n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=data_test,\n",
        "                                              x_col=\"path\", y_col=\"proba\", has_ext=True, \n",
        "                                              class_mode=\"other\", target_size=(IMG_H, IMG_W), \n",
        "                                              batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opHG195HGRyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, Adadelta, SGD\n",
        "\n",
        "def create_model(layers, loss):\n",
        "  pretrained_model = NASNetMobile(weights='imagenet', include_top=False)\n",
        "  pretrained_model.trainable = True\n",
        "\n",
        "  x = pretrained_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  \n",
        "  for layer in layers:\n",
        "    x = Dense(layer)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "  predictions = Dense(1, activation='sigmoid')(x)\n",
        "  model = Model(inputs=pretrained_model.input, outputs=predictions)\n",
        "  model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss=loss, metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFovTpNx-jz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_LAYERS_COUNT = 1\n",
        "MAX_LAYERS_COUNT = 2\n",
        "\n",
        "MIN_NEURONS_COUNT = 300\n",
        "MAX_NEURONS_COUNT = 500\n",
        "NEURON_STEP = 100\n",
        "\n",
        "\n",
        "LAYERS = []\n",
        "LOSSES = ['mse', 'mae']\n",
        "\n",
        "for layer_count in range(MIN_LAYERS_COUNT, MAX_LAYERS_COUNT):\n",
        "  for neuron_count in range(MIN_NEURONS_COUNT, MAX_NEURONS_COUNT, NEURON_STEP):\n",
        "    layers = []\n",
        "    for _ in range(layer_count):\n",
        "      layers.append(neuron_count)\n",
        "      \n",
        "    LAYERS.append(layers)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Hqk5HVaVuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch = data_train.shape[0]//batch_size\n",
        "validation_steps = data_test.shape[0]//batch_size\n",
        "\n",
        "for layers in LAYERS:\n",
        "  for loss in LOSSES:\n",
        "    print(f'Loss: {loss}, Layers: {layers}')\n",
        "    model = create_model(layers, loss)\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=validation_steps,\n",
        "        epochs=10,\n",
        "        verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rufyo3XNTfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch = data_train.shape[0]//batch_size\n",
        "validation_steps = data_test.shape[0]//batch_size\n",
        "\n",
        "model = create_model([1024, 512], 'mse')\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=10,\n",
        "    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfBip33Ipi59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('NASNetMobile_1024_512_mse.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INC9RHJeYrSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test[200:300]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ya1B0ie8O9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "test_predicted = []\n",
        "\n",
        "for i, row in data_test[200:300].iterrows():\n",
        "  test_img = read_image(row['path'])\n",
        "  # plt.imshow(test_img)\n",
        "  # plt.show()\n",
        "  test_img = test_img[None, :,:,:]\n",
        "  predict = model.predict(test_img)[0][0]\n",
        "  test_predicted.append(predict)\n",
        "  print(f'{predict:0.5}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u09ctxpspNvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = 0\n",
        "end = 100\n",
        "count = end - start\n",
        "x = list(range(count))\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.plot(x, test_predicted[start:end], color='yellow')\n",
        "plt.plot(x, data_test['proba'][start:end], color='green')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrkRBYTI7eXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}